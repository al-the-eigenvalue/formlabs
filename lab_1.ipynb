{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "q5ntLF09fxU9"
      },
      "outputs": [],
      "source": [
        "import itertools\n",
        "import sys\n",
        "\n",
        "from collections import defaultdict, deque\n",
        "from typing import List"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Операции и их порядок"
      ],
      "metadata": {
        "id": "QljOwkwvt23s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "OPERATORS = {\"|\", \".\", \"*\", \"+\", \"?\"}\n",
        "OP_PRECEDENCE = {\n",
        "    \"|\": 1,\n",
        "    \".\": 2,\n",
        "    \"*\": 3,\n",
        "    \"+\": 3,\n",
        "    \"?\": 3,\n",
        "}"
      ],
      "metadata": {
        "id": "CM-Zd7uGf3hj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Токенизация регулярок"
      ],
      "metadata": {
        "id": "cqVCkLLht8dN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def add_concat(regex: str) -> list:\n",
        "    tokens = []\n",
        "    i = 0\n",
        "    while i < len(regex):\n",
        "        if regex[i] != \"\\\\\":\n",
        "            tokens.append(regex[i])\n",
        "            i += 1\n",
        "        else:\n",
        "            # we have one or more backslashes\n",
        "            j = i\n",
        "            while i < len(regex) and regex[i] == \"\\\\\":\n",
        "                i += 1\n",
        "            n = i - j\n",
        "            pairs = n // 2\n",
        "            for _ in range(pairs):\n",
        "                # represent a literal backslash by \"\\\\\"\n",
        "                tokens.append(\"\\\\\\\\\")\n",
        "            if n % 2 == 1:\n",
        "                # odd count! last backslash escapes next character\n",
        "                if i < len(regex):\n",
        "                    tokens.append(\"\\\\\" + regex[i])\n",
        "                    i += 1\n",
        "                else:\n",
        "                    # next character does not exist!? treat as literal backslash\n",
        "                    tokens.append(\"\\\\\\\\\")\n",
        "\n",
        "    def is_literal(tok: str) -> bool:\n",
        "        # escaped tokens (start with backslash) are literals\n",
        "        if isinstance(tok, str) and tok.startswith(\"\\\\\"):\n",
        "            return True\n",
        "        # tokens that are operators or parentheses are not literals\n",
        "        if tok in OPERATORS or tok in {\"(\", \")\"}:\n",
        "            return False\n",
        "        return True\n",
        "\n",
        "    out_tokens = []\n",
        "    for idx, tok in enumerate(tokens):\n",
        "        out_tokens.append(tok)\n",
        "        if idx + 1 >= len(tokens):\n",
        "            continue\n",
        "        nxt = tokens[idx + 1]\n",
        "        # left can be end of an atom if it is a literal, a closing parenthesis, or a postfix operator (* + ?)\n",
        "        left_can_end = is_literal(tok) or tok == \")\" or tok in {\"*\", \"+\", \"?\"}\n",
        "        # next can be start of an atom if it is a literal or an opening parenthesis\n",
        "        next_can_start = is_literal(nxt) or nxt == \"(\"\n",
        "        if left_can_end and next_can_start:\n",
        "            out_tokens.append(\".\")\n",
        "\n",
        "    return out_tokens"
      ],
      "metadata": {
        "id": "RqpSQACGj9AB"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "add_concat(\"a(b|c)+\\\\\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wcKc8TV6k1zS",
        "outputId": "df7291c5-04e6-41d1-9f17-75f31a6afb0c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['a', '.', '(', 'b', '|', 'c', ')', '+', '.', '\\\\\\\\']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Reverse Polish Notation"
      ],
      "metadata": {
        "id": "FEFCMImBuBiO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def to_postfix(regex: str) -> str:\n",
        "    tokens = add_concat(regex)\n",
        "    output = []\n",
        "    stack = []\n",
        "    for tok in tokens:\n",
        "        # escaped literal\n",
        "        if tok.startswith(\"\\\\\"):\n",
        "            output.append(tok)\n",
        "        elif tok == \"(\":\n",
        "            stack.append(tok)\n",
        "        elif tok == \")\":\n",
        "            while stack and stack[-1] != \"(\":\n",
        "                output.append(stack.pop())\n",
        "            if not stack:\n",
        "                raise ValueError(\"Mismatched parenthesis\")\n",
        "            stack.pop()\n",
        "        elif tok in OPERATORS:\n",
        "            # unary postfix operators (* + ?), handle precedence\n",
        "            while stack and stack[-1] != \"(\" and (\n",
        "                OP_PRECEDENCE[stack[-1]] > OP_PRECEDENCE[tok] or\n",
        "                (OP_PRECEDENCE[stack[-1]] == OP_PRECEDENCE[tok] and tok not in {\"*\", \"+\", \"?\"})\n",
        "            ):\n",
        "                output.append(stack.pop())\n",
        "            stack.append(tok)\n",
        "        else:\n",
        "            # literal\n",
        "            output.append(tok)\n",
        "    while stack:\n",
        "        op = stack.pop()\n",
        "        if op in \"()\":\n",
        "            raise ValueError(\"Mismatched parenthesis\")\n",
        "        output.append(op)\n",
        "    return \" \".join(output)"
      ],
      "metadata": {
        "id": "EZxYiLkql99x"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "to_postfix(\"a(b|c)+\\\\\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "kQvMXI40owIy",
        "outputId": "ae432f4a-c600-46d7-c6c4-832f91dd34bd"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'a b c | + . \\\\\\\\ .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "to_postfix(\"(a|b)*abb\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "CTQdFa_So7er",
        "outputId": "0fed6e86-5591-491d-969c-e2b545c063e5"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'a b | * a . b . b .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Токены\n",
        "\n",
        "`[\"a\", \".\", \"(\", \"b\", \"|\", \"c\", \")\", \"+\", \".\", \"\\?\"]`\n",
        "\n",
        "\n",
        "tok=`a` → обычный символ → `output = [\"a\"]`, `stack = []`\n",
        "\n",
        "tok=`.` → оператор → `stack = [\".\"]`\n",
        "\n",
        "tok=`(` → добавляем в стек → `stack = [\".\", \"(\"]`\n",
        "\n",
        "tok=`b` → обычный символ → `output = [\"a\", \"b\"]`\n",
        "\n",
        "tok=`|` → оператор → `stack = [\".\", \"(\", \"|\"]`\n",
        "\n",
        "tok=`c` → обычный символ → `output = [\"a\", \"b\", \"c\"]`\n",
        "\n",
        "tok=`)` → переносим содержимое скобок из стека в output → `output = [\"a\", \"b\",\"c\", \"|\"]`, `stack = [\".\"]`\n",
        "\n",
        "tok=`+` → оператор, приоритет выше чем у `\".\"`, убираем из стека → `stack = [\".\", \"+\"]`\n",
        "\n",
        "tok=`.` → оператор, приоритет ниже чем у `\"+\"` → убираем `\"+\"` из стека → `output = [\"a\", \"b\", \"c\", \"|\", \"+\"], stack = [\".\"]`, теперь верхний элемент в стеке такой же, как новый токен, кладем в output → `output = [\"a\", \"b\", \"c\", \"|\", \"+\", \".\"]`; кладем `\".\"` в стек → `stack = [\".\"]`\n",
        "\n",
        "tok=`\\?` → обычный символ → `output = [\"a\", \"b\", \"c\", \"|\", \"+\", \".\", \"\\?\"]`\n",
        "\n",
        "в конце смердживаем стек в конец output\n",
        "`[\"a\", \"b\", \"c\", \"|\", \"+\", \".\", \"\\?\", \".\"]` превращается в строку `a b c | + . \\? .`"
      ],
      "metadata": {
        "id": "c77xytUOttfS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Класс для состояния"
      ],
      "metadata": {
        "id": "YA5_yEklvvpW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class State:\n",
        "    _ids = itertools.count()\n",
        "    def __init__(self):\n",
        "        self.id = next(State._ids)\n",
        "        # transitions: symbol -> set(states)\n",
        "        self.transitions = defaultdict(set)\n",
        "    def add(self, sym, st):\n",
        "        # sym is character or None for epsilon\n",
        "        self.transitions[sym].add(st)\n",
        "    def __repr__(self):\n",
        "        return f\"S{self.id}\""
      ],
      "metadata": {
        "id": "k0hdgdUKsGsz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Класс для недетерминированного конечного автомата (граф из State)"
      ],
      "metadata": {
        "id": "qyDUyHjZwNGY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NFA:\n",
        "    def __init__(self, start: State, accept: State):\n",
        "        self.start = start\n",
        "        self.accept = accept\n",
        "        self.states = set()\n",
        "        self._gather()\n",
        "\n",
        "    def _gather(self):\n",
        "        # BFS to collect states\n",
        "        q = deque([self.start])\n",
        "        seen = set([self.start])\n",
        "        while q:\n",
        "            s = q.popleft()\n",
        "            self.states.add(s)\n",
        "            for targets in s.transitions.values():\n",
        "                for t in targets:\n",
        "                    if t not in seen:\n",
        "                        seen.add(t)\n",
        "                        q.append(t)\n",
        "\n",
        "    @staticmethod\n",
        "    def single(symbol):\n",
        "        # creates the simplest possible NFA for a single symbol\n",
        "        s = State()\n",
        "        a = State()\n",
        "        s.add(symbol, a)\n",
        "        return NFA(s, a)\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"NFA(start={self.start}, accept={self.accept}, states={len(self.states)})\""
      ],
      "metadata": {
        "id": "M1UZ89EOwKWG"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Построение НКА"
      ],
      "metadata": {
        "id": "wPdh4oQX6Ii1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def build_nfa_from_postfix(postfix: str) -> NFA:\n",
        "    tokens = postfix.split()\n",
        "    stack = []\n",
        "    for tok in tokens:\n",
        "        if tok.startswith(\"\\\\\"):\n",
        "            if len(tok) == 1:\n",
        "                literal = \"\\\\\"\n",
        "            else:\n",
        "                literal = tok[1]\n",
        "            stack.append(NFA.single(literal))\n",
        "        elif tok not in OPERATORS:\n",
        "            stack.append(NFA.single(tok))\n",
        "        else:\n",
        "            if tok == \".\":\n",
        "                # concatenation. connect a.accept -> b.start (via epsilon)\n",
        "                b = stack.pop()\n",
        "                a = stack.pop()\n",
        "                a.accept.add(None, b.start)\n",
        "                n = NFA(a.start, b.accept)\n",
        "                stack.append(n)\n",
        "            elif tok == \"|\":\n",
        "                b = stack.pop()\n",
        "                a = stack.pop()\n",
        "                s = State()\n",
        "                f = State()\n",
        "                s.add(None, a.start)\n",
        "                s.add(None, b.start)\n",
        "                a.accept.add(None, f)\n",
        "                b.accept.add(None, f)\n",
        "                stack.append(NFA(s, f))\n",
        "            elif tok == \"*\":\n",
        "                a = stack.pop()\n",
        "                s = State()\n",
        "                f = State()\n",
        "                s.add(None, a.start)\n",
        "                s.add(None, f)\n",
        "                a.accept.add(None, a.start)\n",
        "                a.accept.add(None, f)\n",
        "                stack.append(NFA(s, f))\n",
        "            elif tok == \"+\":\n",
        "                a = stack.pop()\n",
        "                # A+ = A . A*\n",
        "                s = State()\n",
        "                f = State()\n",
        "                s.add(None, a.start)\n",
        "                a.accept.add(None, a.start)\n",
        "                a.accept.add(None, f)\n",
        "                stack.append(NFA(s, f))\n",
        "            elif tok == \"?\":\n",
        "                a = stack.pop()\n",
        "                s = State()\n",
        "                f = State()\n",
        "                s.add(None, a.start)\n",
        "                s.add(None, f)\n",
        "                a.accept.add(None, f)\n",
        "                stack.append(NFA(s, f))\n",
        "            else:\n",
        "                raise ValueError(f\"Unknown operator {tok}\")\n",
        "    if len(stack) != 1:\n",
        "        raise ValueError(\"Invalid regex: stack leftover\")\n",
        "    return stack[0]"
      ],
      "metadata": {
        "id": "TtOK92GM6KsQ"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Избавление от е-дуг"
      ],
      "metadata": {
        "id": "XmkAA8deENNP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class EpsilonFreeNFA:\n",
        "    def __init__(self, start, accepts, transitions, alphabet, states):\n",
        "        self.start = start\n",
        "        self.accepts = set(accepts)\n",
        "        self.transitions = transitions  # dict state -> dict symbol -> set(states)\n",
        "        self.alphabet = set(alphabet)\n",
        "        self.states = set(states)"
      ],
      "metadata": {
        "id": "dQCga8SrGQKp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def epsilon_closure(states):\n",
        "    # states: iterable of State objects\n",
        "    stack = list(states)\n",
        "    res = set(stack)\n",
        "    while stack:\n",
        "        s = stack.pop()\n",
        "        for t in s.transitions.get(None, []):\n",
        "            if t not in res:\n",
        "                res.add(t); stack.append(t)\n",
        "    return res"
      ],
      "metadata": {
        "id": "HQJJv66UFfbp"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def remove_epsilon(nfa: NFA):\n",
        "    # Build mapping state -> closure using original NFA\n",
        "    closures = {s: epsilon_closure([s]) for s in nfa.states}\n",
        "    # Determine alphabet (exclude None)\n",
        "    alphabet = set()\n",
        "    for s in nfa.states:\n",
        "        for sym in s.transitions.keys():\n",
        "            if sym is not None:\n",
        "                alphabet.add(sym)\n",
        "    # New transitions: for each state p and symbol a,\n",
        "    # targets = union over q in closure(p) of transitions on a from q, then take closure of each target\n",
        "    new_transitions = {s: defaultdict(set) for s in nfa.states}\n",
        "    for p in nfa.states:\n",
        "        for a in alphabet:\n",
        "            targets = set()\n",
        "            for q in closures[p]:\n",
        "                for t in q.transitions.get(a, []):\n",
        "                    targets.update(closures[t])\n",
        "            if targets:\n",
        "                new_transitions[p][a] = targets\n",
        "    # New accept states: any state p such that closure(p) contains original accept\n",
        "    new_accepts = set()\n",
        "    for p in nfa.states:\n",
        "        if nfa.accept in closures[p]:\n",
        "            new_accepts.add(p)\n",
        "\n",
        "    return EpsilonFreeNFA(nfa.start, new_accepts, new_transitions, alphabet, nfa.states)"
      ],
      "metadata": {
        "id": "Ev8zHgxmEMs6"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Класс для ДКА"
      ],
      "metadata": {
        "id": "Dt1v5mI1FUp5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DFA:\n",
        "    def __init__(self, start, accepts, transitions, alphabet):\n",
        "        self.start = start\n",
        "        self.accepts = set(accepts)\n",
        "        self.transitions = transitions\n",
        "        self.alphabet = alphabet\n",
        "        self.states = set(transitions.keys())"
      ],
      "metadata": {
        "id": "vdvAoM3mFRtd"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Переход от НКА к ДКА"
      ],
      "metadata": {
        "id": "yXUgupCcFa7J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def nfa_to_dfa(ef_nfa):\n",
        "    # State in DFA is frozenset of NFA states\n",
        "    start_set = frozenset([ef_nfa.start])\n",
        "\n",
        "    queue = deque([start_set])\n",
        "    dfa_states = {start_set: 0}\n",
        "    dfa_transitions = {}\n",
        "    dfa_accepts = set()\n",
        "    alph = sorted(list(ef_nfa.alphabet))\n",
        "    while queue:\n",
        "        S = queue.popleft()\n",
        "        sid = dfa_states[S]\n",
        "        dfa_transitions[sid] = {}\n",
        "        # if any NFA state in S is accepting -> DFA accepting\n",
        "        if any(s in ef_nfa.accepts for s in S):\n",
        "            dfa_accepts.add(sid)\n",
        "        for a in alph:\n",
        "            # move: for each nfa state in S, union ef_nfa.transitions[state].get(a, [])\n",
        "            dest = set()\n",
        "            for p in S:\n",
        "                dest.update(ef_nfa.transitions.get(p, {}).get(a, set()))\n",
        "            dest = frozenset(dest)\n",
        "            if not dest:\n",
        "                continue\n",
        "            if dest not in dfa_states:\n",
        "                dfa_states[dest] = len(dfa_states)\n",
        "                queue.append(dest)\n",
        "            dfa_transitions[sid][a] = dfa_states[dest]\n",
        "\n",
        "    return DFA(0, dfa_accepts, dfa_transitions, alph)"
      ],
      "metadata": {
        "id": "xDFxEVVqFaca"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Оптимизация ДКА"
      ],
      "metadata": {
        "id": "zvCXeeoPGpuE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def minimize_dfa(dfa):\n",
        "    # states are ints 0..n-1\n",
        "    states = set(dfa.transitions.keys())\n",
        "    alphabet = list(dfa.alphabet)\n",
        "    # initialize partitions: accepting and non-accepting\n",
        "    P = [set(dfa.accepts), states - set(dfa.accepts)]\n",
        "    P = [s for s in P if s]  # remove empty\n",
        "    # worklist\n",
        "    W = deque(P.copy())\n",
        "    inv = defaultdict(lambda: defaultdict(set))  # inv[a][q] = set of p that transition on a to q\n",
        "    for p in states:\n",
        "        for a in alphabet:\n",
        "            q = dfa.transitions.get(p, {}).get(a, None)\n",
        "            if q is not None:\n",
        "                inv[a][q].add(p)\n",
        "    while W:\n",
        "        A = W.popleft()\n",
        "        for a in alphabet:\n",
        "            # X = states that have transitions on a to A\n",
        "            X = set()\n",
        "            for q in A:\n",
        "                X.update(inv[a].get(q, set()))\n",
        "            if not X:\n",
        "                continue\n",
        "            newP = []\n",
        "            for Y in P:\n",
        "                inter = Y & X\n",
        "                diff = Y - X\n",
        "                if inter and diff:\n",
        "                    newP.append(inter)\n",
        "                    newP.append(diff)\n",
        "                    # replace Y in P by inter and diff\n",
        "                    P = [p_ for p_ in P if p_ is not Y]\n",
        "                    P.extend([inter, diff])\n",
        "                    # adjust worklist\n",
        "                    if Y in W:\n",
        "                        W.remove(Y)\n",
        "                        W.append(inter); W.append(diff)\n",
        "                    else:\n",
        "                        # add smaller\n",
        "                        W.append(inter if len(inter) <= len(diff) else diff)\n",
        "                    break\n",
        "            # continue looping over P until stable\n",
        "\n",
        "    # Now P contains partition blocks; build new DFA\n",
        "    # map old state -> block id\n",
        "    block_of = {}\n",
        "    for i,block in enumerate(P):\n",
        "        for s in block:\n",
        "            block_of[s] = i\n",
        "    new_start = block_of[dfa.start]\n",
        "    new_accepts = set()\n",
        "    for b_idx, block in enumerate(P):\n",
        "        if any(s in dfa.accepts for s in block):\n",
        "            new_accepts.add(b_idx)\n",
        "    new_transitions = {}\n",
        "    for b_idx, block in enumerate(P):\n",
        "        # choose representative\n",
        "        rep = next(iter(block))\n",
        "        new_transitions[b_idx] = {}\n",
        "        for a in alphabet:\n",
        "            q = dfa.transitions.get(rep, {}).get(a, None)\n",
        "            if q is not None:\n",
        "                new_transitions[b_idx][a] = block_of[q]\n",
        "\n",
        "    return DFA(new_start, new_accepts, new_transitions, alphabet)"
      ],
      "metadata": {
        "id": "_BGYPKrXGauz"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def match_dfa(dfa, s: str) -> bool:\n",
        "    cur = dfa.start\n",
        "    for ch in s:\n",
        "        if ch not in dfa.alphabet:\n",
        "            return False\n",
        "        cur = dfa.transitions.get(cur, {}).get(ch, None)\n",
        "        if cur is None:\n",
        "            return False\n",
        "    return cur in dfa.accepts"
      ],
      "metadata": {
        "id": "_rlX4pQ0Gii-"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Принты"
      ],
      "metadata": {
        "id": "Wh6JPbDAG72w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pretty_print_nfa(nfa: NFA):\n",
        "    print(\"NFA states:\", len(nfa.states))\n",
        "    for s in sorted(nfa.states, key=lambda x: x.id):\n",
        "        for sym, targets in s.transitions.items():\n",
        "            for t in targets:\n",
        "                print(f\"  {s} -[{sym if sym is not None else \"ε\"}]-> {t}\")\n",
        "    print(\"Start:\", nfa.start, \"Accept:\", nfa.accept)\n",
        "\n",
        "\n",
        "def pretty_print_efnfa(ef):\n",
        "    print(\"Epsilon-free NFA states:\", len(ef.states))\n",
        "    for s in sorted(ef.states, key=lambda x: x.id):\n",
        "        for a, targets in ef.transitions.get(s, {}).items():\n",
        "            for t in targets:\n",
        "                print(f\"  {s} -[{a}]-> {t}\")\n",
        "    print(\"Start:\", ef.start, \"Accepts:\", ef.accepts)\n",
        "\n",
        "\n",
        "def pretty_print_dfa(dfa):\n",
        "    print(\"DFA states:\", len(dfa.transitions))\n",
        "    for s in sorted(dfa.transitions.keys()):\n",
        "        for a, t in dfa.transitions[s].items():\n",
        "            print(f\"  D{s} -[{a}]-> D{t}\")\n",
        "    print(\"Start:\", dfa.start, \"Accepts:\", dfa.accepts)"
      ],
      "metadata": {
        "id": "tu0UEtRoGtX3"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Проверка"
      ],
      "metadata": {
        "id": "HCg1fgHxIUNb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compile_regex(regex: str):\n",
        "    postfix = to_postfix(regex)\n",
        "    nfa = build_nfa_from_postfix(postfix)\n",
        "    ef = remove_epsilon(nfa)\n",
        "    dfa = nfa_to_dfa(ef)\n",
        "    min_dfa = minimize_dfa(dfa)\n",
        "    return {\n",
        "        \"postfix\": postfix,\n",
        "        \"nfa\": nfa,\n",
        "        \"ef_nfa\": ef,\n",
        "        \"dfa\": dfa,\n",
        "        \"min_dfa\": min_dfa,\n",
        "    }"
      ],
      "metadata": {
        "id": "yygBhCupHEQt"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_regex(regex: str, statements: List[str]):\n",
        "    compiled = compile_regex(regex)\n",
        "    print(\"Постфикс:\", compiled[\"postfix\"])\n",
        "    print(\"NFA states:\", len(compiled[\"nfa\"].states))\n",
        "    print(\"Epsilon-free NFA states:\", len(compiled[\"ef_nfa\"].states))\n",
        "    print(\"DFA states (before minimization):\", len(compiled[\"dfa\"].transitions))\n",
        "    print(\"DFA states (after minimization):\", len(compiled[\"min_dfa\"].transitions))\n",
        "    print(\"\\n--- NFA ---\")\n",
        "    pretty_print_nfa(compiled[\"nfa\"])\n",
        "    print(\"\\n--- Epsilon-free NFA ---\")\n",
        "    pretty_print_efnfa(compiled[\"ef_nfa\"])\n",
        "    print(\"\\n--- DFA ---\")\n",
        "    pretty_print_dfa(compiled[\"dfa\"])\n",
        "    print(\"\\n--- Minimized DFA ---\")\n",
        "    pretty_print_dfa(compiled[\"min_dfa\"])\n",
        "    print(\"\\nValidating examples\\n\")\n",
        "    for statement in statements:\n",
        "        print(statement)\n",
        "        ok = match_dfa(compiled[\"min_dfa\"], statement)\n",
        "        print(\"ACCEPT\" if ok else \"REJECT\")\n",
        "        print()"
      ],
      "metadata": {
        "id": "HGfpxfcXHMIj"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validate_regex(\n",
        "    regex=\"a(b|c)+\\\\\",\n",
        "    statements=[\n",
        "        \"abc\",           # REJECT\n",
        "        \"ab\\\\\",          # ACCEPT\n",
        "        \"ac\\\\\",          # ACCEPT\n",
        "        \"a\\\\\",           # REJECT\n",
        "        \"abc\\\\\",         # ACCEPT\n",
        "        \"abcbcbcbb\\\\\",   # ACCEPT\n",
        "        \"b\\\\\"            # REJECT\n",
        "    ]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wkYg40LwHq-g",
        "outputId": "f9e226cb-dc66-4f54-c426-5afbd797b91b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Постфикс: a b c | + . \\\\ .\n",
            "NFA states: 12\n",
            "Epsilon-free NFA states: 12\n",
            "DFA states (before minimization): 5\n",
            "DFA states (after minimization): 4\n",
            "\n",
            "--- NFA ---\n",
            "NFA states: 12\n",
            "  S0 -[a]-> S1\n",
            "  S1 -[ε]-> S8\n",
            "  S2 -[b]-> S3\n",
            "  S3 -[ε]-> S7\n",
            "  S4 -[c]-> S5\n",
            "  S5 -[ε]-> S7\n",
            "  S6 -[ε]-> S4\n",
            "  S6 -[ε]-> S2\n",
            "  S7 -[ε]-> S9\n",
            "  S7 -[ε]-> S6\n",
            "  S8 -[ε]-> S6\n",
            "  S9 -[ε]-> S10\n",
            "  S10 -[\\]-> S11\n",
            "Start: S0 Accept: S11\n",
            "\n",
            "--- Epsilon-free NFA ---\n",
            "Epsilon-free NFA states: 12\n",
            "  S0 -[a]-> S4\n",
            "  S0 -[a]-> S8\n",
            "  S0 -[a]-> S1\n",
            "  S0 -[a]-> S2\n",
            "  S0 -[a]-> S6\n",
            "  S1 -[c]-> S4\n",
            "  S1 -[c]-> S9\n",
            "  S1 -[c]-> S5\n",
            "  S1 -[c]-> S10\n",
            "  S1 -[c]-> S2\n",
            "  S1 -[c]-> S7\n",
            "  S1 -[c]-> S6\n",
            "  S1 -[b]-> S4\n",
            "  S1 -[b]-> S3\n",
            "  S1 -[b]-> S9\n",
            "  S1 -[b]-> S7\n",
            "  S1 -[b]-> S10\n",
            "  S1 -[b]-> S2\n",
            "  S1 -[b]-> S6\n",
            "  S2 -[b]-> S4\n",
            "  S2 -[b]-> S3\n",
            "  S2 -[b]-> S9\n",
            "  S2 -[b]-> S7\n",
            "  S2 -[b]-> S10\n",
            "  S2 -[b]-> S2\n",
            "  S2 -[b]-> S6\n",
            "  S3 -[c]-> S4\n",
            "  S3 -[c]-> S9\n",
            "  S3 -[c]-> S5\n",
            "  S3 -[c]-> S10\n",
            "  S3 -[c]-> S2\n",
            "  S3 -[c]-> S7\n",
            "  S3 -[c]-> S6\n",
            "  S3 -[\\]-> S11\n",
            "  S3 -[b]-> S4\n",
            "  S3 -[b]-> S3\n",
            "  S3 -[b]-> S9\n",
            "  S3 -[b]-> S7\n",
            "  S3 -[b]-> S10\n",
            "  S3 -[b]-> S2\n",
            "  S3 -[b]-> S6\n",
            "  S4 -[c]-> S4\n",
            "  S4 -[c]-> S9\n",
            "  S4 -[c]-> S5\n",
            "  S4 -[c]-> S10\n",
            "  S4 -[c]-> S2\n",
            "  S4 -[c]-> S7\n",
            "  S4 -[c]-> S6\n",
            "  S5 -[c]-> S4\n",
            "  S5 -[c]-> S9\n",
            "  S5 -[c]-> S5\n",
            "  S5 -[c]-> S10\n",
            "  S5 -[c]-> S2\n",
            "  S5 -[c]-> S7\n",
            "  S5 -[c]-> S6\n",
            "  S5 -[\\]-> S11\n",
            "  S5 -[b]-> S4\n",
            "  S5 -[b]-> S3\n",
            "  S5 -[b]-> S9\n",
            "  S5 -[b]-> S7\n",
            "  S5 -[b]-> S10\n",
            "  S5 -[b]-> S2\n",
            "  S5 -[b]-> S6\n",
            "  S6 -[c]-> S4\n",
            "  S6 -[c]-> S9\n",
            "  S6 -[c]-> S5\n",
            "  S6 -[c]-> S10\n",
            "  S6 -[c]-> S2\n",
            "  S6 -[c]-> S7\n",
            "  S6 -[c]-> S6\n",
            "  S6 -[b]-> S4\n",
            "  S6 -[b]-> S3\n",
            "  S6 -[b]-> S9\n",
            "  S6 -[b]-> S7\n",
            "  S6 -[b]-> S10\n",
            "  S6 -[b]-> S2\n",
            "  S6 -[b]-> S6\n",
            "  S7 -[c]-> S4\n",
            "  S7 -[c]-> S9\n",
            "  S7 -[c]-> S5\n",
            "  S7 -[c]-> S10\n",
            "  S7 -[c]-> S2\n",
            "  S7 -[c]-> S7\n",
            "  S7 -[c]-> S6\n",
            "  S7 -[\\]-> S11\n",
            "  S7 -[b]-> S4\n",
            "  S7 -[b]-> S3\n",
            "  S7 -[b]-> S9\n",
            "  S7 -[b]-> S7\n",
            "  S7 -[b]-> S10\n",
            "  S7 -[b]-> S2\n",
            "  S7 -[b]-> S6\n",
            "  S8 -[c]-> S4\n",
            "  S8 -[c]-> S9\n",
            "  S8 -[c]-> S5\n",
            "  S8 -[c]-> S10\n",
            "  S8 -[c]-> S2\n",
            "  S8 -[c]-> S7\n",
            "  S8 -[c]-> S6\n",
            "  S8 -[b]-> S4\n",
            "  S8 -[b]-> S3\n",
            "  S8 -[b]-> S9\n",
            "  S8 -[b]-> S7\n",
            "  S8 -[b]-> S10\n",
            "  S8 -[b]-> S2\n",
            "  S8 -[b]-> S6\n",
            "  S9 -[\\]-> S11\n",
            "  S10 -[\\]-> S11\n",
            "Start: S0 Accepts: {S11}\n",
            "\n",
            "--- DFA ---\n",
            "DFA states: 5\n",
            "  D0 -[a]-> D1\n",
            "  D1 -[b]-> D2\n",
            "  D1 -[c]-> D3\n",
            "  D2 -[\\]-> D4\n",
            "  D2 -[b]-> D2\n",
            "  D2 -[c]-> D3\n",
            "  D3 -[\\]-> D4\n",
            "  D3 -[b]-> D2\n",
            "  D3 -[c]-> D3\n",
            "Start: 0 Accepts: {4}\n",
            "\n",
            "--- Minimized DFA ---\n",
            "DFA states: 4\n",
            "  D1 -[\\]-> D0\n",
            "  D1 -[b]-> D1\n",
            "  D1 -[c]-> D1\n",
            "  D2 -[b]-> D1\n",
            "  D2 -[c]-> D1\n",
            "  D3 -[a]-> D2\n",
            "Start: 3 Accepts: {0}\n",
            "\n",
            "Validating examples\n",
            "\n",
            "abc\n",
            "REJECT\n",
            "\n",
            "ab\\\n",
            "ACCEPT\n",
            "\n",
            "ac\\\n",
            "ACCEPT\n",
            "\n",
            "a\\\n",
            "REJECT\n",
            "\n",
            "abc\\\n",
            "ACCEPT\n",
            "\n",
            "abcbcbcbb\\\n",
            "ACCEPT\n",
            "\n",
            "b\\\n",
            "REJECT\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "validate_regex(\n",
        "    regex=r\"(ab\\?c)+d?\",\n",
        "    statements=[\n",
        "        \"ab?c\",          # ACCEPT\n",
        "        \"ab?cab?c\",      # ACCEPT\n",
        "        \"ab?cd\",         # ACCEPT\n",
        "        \"ab?cab?cd\",     # ACCEPT\n",
        "        \"abc\",           # REJECT\n",
        "        \"ab??c\",         # REJECT\n",
        "        \"ab?cab?cdd\",    # REJECT\n",
        "        \"d\",             # REJECT\n",
        "    ]\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EyEFXSy_JL-t",
        "outputId": "786fa082-6fdb-455f-a26c-dd6fed883940"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Постфикс: a b . \\? . c . + d ? .\n",
            "NFA states: 14\n",
            "Epsilon-free NFA states: 14\n",
            "DFA states (before minimization): 6\n",
            "DFA states (after minimization): 6\n",
            "\n",
            "--- NFA ---\n",
            "NFA states: 14\n",
            "  S12 -[a]-> S13\n",
            "  S13 -[ε]-> S14\n",
            "  S14 -[b]-> S15\n",
            "  S15 -[ε]-> S16\n",
            "  S16 -[?]-> S17\n",
            "  S17 -[ε]-> S18\n",
            "  S18 -[c]-> S19\n",
            "  S19 -[ε]-> S12\n",
            "  S19 -[ε]-> S21\n",
            "  S20 -[ε]-> S12\n",
            "  S21 -[ε]-> S24\n",
            "  S22 -[d]-> S23\n",
            "  S23 -[ε]-> S25\n",
            "  S24 -[ε]-> S25\n",
            "  S24 -[ε]-> S22\n",
            "Start: S20 Accept: S25\n",
            "\n",
            "--- Epsilon-free NFA ---\n",
            "Epsilon-free NFA states: 14\n",
            "  S12 -[a]-> S13\n",
            "  S12 -[a]-> S14\n",
            "  S13 -[b]-> S16\n",
            "  S13 -[b]-> S15\n",
            "  S14 -[b]-> S16\n",
            "  S14 -[b]-> S15\n",
            "  S15 -[?]-> S17\n",
            "  S15 -[?]-> S18\n",
            "  S16 -[?]-> S17\n",
            "  S16 -[?]-> S18\n",
            "  S17 -[c]-> S22\n",
            "  S17 -[c]-> S21\n",
            "  S17 -[c]-> S25\n",
            "  S17 -[c]-> S12\n",
            "  S17 -[c]-> S19\n",
            "  S17 -[c]-> S24\n",
            "  S18 -[c]-> S22\n",
            "  S18 -[c]-> S21\n",
            "  S18 -[c]-> S25\n",
            "  S18 -[c]-> S12\n",
            "  S18 -[c]-> S19\n",
            "  S18 -[c]-> S24\n",
            "  S19 -[d]-> S25\n",
            "  S19 -[d]-> S23\n",
            "  S19 -[a]-> S13\n",
            "  S19 -[a]-> S14\n",
            "  S20 -[a]-> S13\n",
            "  S20 -[a]-> S14\n",
            "  S21 -[d]-> S25\n",
            "  S21 -[d]-> S23\n",
            "  S22 -[d]-> S25\n",
            "  S22 -[d]-> S23\n",
            "  S24 -[d]-> S25\n",
            "  S24 -[d]-> S23\n",
            "Start: S20 Accepts: {S23, S21, S25, S19, S24}\n",
            "\n",
            "--- DFA ---\n",
            "DFA states: 6\n",
            "  D0 -[a]-> D1\n",
            "  D1 -[b]-> D2\n",
            "  D2 -[?]-> D3\n",
            "  D3 -[c]-> D4\n",
            "  D4 -[a]-> D1\n",
            "  D4 -[d]-> D5\n",
            "Start: 0 Accepts: {4, 5}\n",
            "\n",
            "--- Minimized DFA ---\n",
            "DFA states: 6\n",
            "  D0 -[c]-> D1\n",
            "  D1 -[a]-> D4\n",
            "  D1 -[d]-> D2\n",
            "  D3 -[?]-> D0\n",
            "  D4 -[b]-> D3\n",
            "  D5 -[a]-> D4\n",
            "Start: 5 Accepts: {1, 2}\n",
            "\n",
            "Validating examples\n",
            "\n",
            "ab?c\n",
            "ACCEPT\n",
            "\n",
            "ab?cab?c\n",
            "ACCEPT\n",
            "\n",
            "ab?cd\n",
            "ACCEPT\n",
            "\n",
            "ab?cab?cd\n",
            "ACCEPT\n",
            "\n",
            "abc\n",
            "REJECT\n",
            "\n",
            "ab??c\n",
            "REJECT\n",
            "\n",
            "ab?cab?cdd\n",
            "REJECT\n",
            "\n",
            "d\n",
            "REJECT\n",
            "\n"
          ]
        }
      ]
    }
  ]
}